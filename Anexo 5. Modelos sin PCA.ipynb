{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ALEJANDRO RENDON\\Downloads\\data_prepd_train_no_pca.csv\")\n",
    "index = df['Customer_ID']\n",
    "y = df['Credit_Score']\n",
    "X = df.drop(['Credit_Score','Customer_ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [   16    17    18 ... 99965 99966 99967] Test: [    0     1     2 ... 99997 99998 99999]\n",
      "Train: [    0     1     2 ... 99989 99990 99991] Test: [    8     9    10 ... 99997 99998 99999]\n"
     ]
    }
   ],
   "source": [
    "gss = GroupShuffleSplit(n_splits=2, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in gss.split(X, groups=index):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X.iloc[test_index, :]\n",
    "    y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5878 1350 1549]\n",
      " [3631 8083 4333]\n",
      " [ 117  804 4255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66970   0.61064   0.63881      9626\n",
      "           1    0.50371   0.78959   0.61505     10237\n",
      "           2    0.82206   0.41975   0.55574     10137\n",
      "\n",
      "    accuracy                        0.60720     30000\n",
      "   macro avg    0.66516   0.60666   0.60320     30000\n",
      "weighted avg    0.66454   0.60720   0.60263     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MLogit = LogisticRegression(class_weight='balanced', random_state=42,max_iter=500, multi_class='multinomial',solver='saga',n_jobs=-1)\n",
    "MLogit.fit(X_train,y_train)\n",
    "y_pred = MLogit.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridMLogit = { \n",
    "    'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.0,0.25,0.5,0.75,1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 856, in _logistic_regression_path\n",
      "    beta = 1.0 / C\n",
      "ZeroDivisionError: float division by zero\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 858, in _logistic_regression_path\n",
      "    alpha = 1.0 / C\n",
      "ZeroDivisionError: float division by zero\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.60413446 0.60422237 0.60414892\n",
      "        nan 0.60413446 0.60402506 0.60414716        nan 0.60413446\n",
      " 0.60404947 0.60414771        nan 0.60413446 0.6040218  0.60416044\n",
      "        nan 0.60413446]\n",
      "  warnings.warn(\n",
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.25, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_MLogit = GridSearchCV(estimator=MLogit, param_grid=param_gridMLogit, cv= 5,scoring='f1_macro')\n",
    "CV_MLogit.fit(X_train, y_train)\n",
    "CV_MLogit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5880 1345 1552]\n",
      " [3630 8088 4329]\n",
      " [ 116  802 4258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66993   0.61085   0.63903      9626\n",
      "           1    0.50402   0.79023   0.61548     10235\n",
      "           2    0.82264   0.41996   0.55606     10139\n",
      "\n",
      "    accuracy                        0.60753     30000\n",
      "   macro avg    0.66553   0.60701   0.60352     30000\n",
      "weighted avg    0.66494   0.60753   0.60295     30000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rendonjimenez.5\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MLogit2 = LogisticRegression(class_weight='balanced', random_state=42,max_iter=500, multi_class='multinomial',solver='saga',C=0.25,penalty='l1',n_jobs=16)\n",
    "MLogit2.fit(X_train,y_train)\n",
    "y_pred = MLogit2.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.60605055, 0.60446279, 0.61005748, 0.59093472, 0.60960632]), 0.6042223731843908]\n"
     ]
    }
   ],
   "source": [
    "CVSMLogit2 = cross_val_score(MLogit2, X_train,y_train, cv=5,scoring='f1_macro')\n",
    "print([CVSMLogit2,np.average(CVSMLogit2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5567  2935   275]\n",
      " [ 1956 12789  1302]\n",
      " [   38  2776  2362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63427   0.73628   0.68148      7561\n",
      "           1    0.79697   0.69130   0.74038     18500\n",
      "           2    0.45634   0.59964   0.51827      3939\n",
      "\n",
      "    accuracy                        0.69060     30000\n",
      "   macro avg    0.62919   0.67574   0.64671     30000\n",
      "weighted avg    0.71124   0.69060   0.69637     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RCF = RandomForestClassifier(random_state=42,n_jobs=-1, n_estimators=500,class_weight='balanced')\n",
    "RCF.fit(X_train,y_train)\n",
    "y_pred = RCF.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridRCF = { \n",
    "    'max_depth' : np.linspace(10,25,26,dtype=int)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_RCF = GridSearchCV(estimator=RCF, param_grid=param_gridRCF, cv= 5,scoring='f1_macro',n_jobs=-1)\n",
    "CV_RCF.fit(X_train, y_train)\n",
    "CV_RCF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6161  1846   770]\n",
      " [ 2840 10739  2468]\n",
      " [   64  1535  3577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70195   0.67965   0.69062      9065\n",
      "           1    0.66922   0.76055   0.71197     14120\n",
      "           2    0.69107   0.52487   0.59661      6815\n",
      "\n",
      "    accuracy                        0.68257     30000\n",
      "   macro avg    0.68741   0.65502   0.66640     30000\n",
      "weighted avg    0.68407   0.68257   0.67931     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RCF2 = RandomForestClassifier(random_state=42,n_jobs=-1,max_depth=20,n_estimators=500,class_weight='balanced')\n",
    "RCF2.fit(X_train,y_train)\n",
    "y_pred = RCF2.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.66083454, 0.65674361, 0.66590293, 0.6467015 , 0.66174081]), 0.6583846783922173]\n"
     ]
    }
   ],
   "source": [
    "CVSRCF2 = cross_val_score(RCF2, X_train,y_train, cv=5,scoring='f1_macro',n_jobs=-1)\n",
    "print([CVSRCF2,np.average(CVSRCF2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6685  986 1106]\n",
      " [3643 8795 3609]\n",
      " [ 128  804 4244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76165   0.63935   0.69516     10456\n",
      "           1    0.54808   0.83089   0.66048     10585\n",
      "           2    0.81994   0.47371   0.60050      8959\n",
      "\n",
      "    accuracy                        0.65747     30000\n",
      "   macro avg    0.70989   0.64798   0.65205     30000\n",
      "weighted avg    0.70370   0.65747   0.65465     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGBM = lgb.LGBMClassifier(random_state=42,n_jobs=-1,n_estimators=500,objective='multiclass',class_weight='balanced',learning_rate=0.01)\n",
    "LGBM.fit(X_train,y_train)\n",
    "y_pred = LGBM.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridLGBM = { \n",
    "    'max_depth' : np.linspace(10,25,26,dtype=int)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_LGBM = GridSearchCV(estimator=LGBM, param_grid=param_gridLGBM, cv= 5,scoring='f1_macro',n_jobs=-1)\n",
    "CV_LGBM.fit(X_train, y_train)\n",
    "CV_LGBM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6692  975 1110]\n",
      " [3637 8793 3617]\n",
      " [ 126  796 4254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.76245   0.64008   0.69592     10455\n",
      "           1    0.54795   0.83236   0.66085     10564\n",
      "           2    0.82187   0.47367   0.60097      8981\n",
      "\n",
      "    accuracy                        0.65797     30000\n",
      "   macro avg    0.71076   0.64870   0.65258     30000\n",
      "weighted avg    0.70471   0.65797   0.65515     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGBM2 = lgb.LGBMClassifier(random_state=42,n_jobs=-1,max_depth=15,n_estimators=500,objective='multiclass',class_weight='balanced',learning_rate=0.01)\n",
    "LGBM2.fit(X_train,y_train)\n",
    "y_pred = LGBM2.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.64759915, 0.64781597, 0.65982856, 0.63842098, 0.66442574]), 0.6516180801959485]\n"
     ]
    }
   ],
   "source": [
    "CVSLGBM2 = cross_val_score(LGBM2, X_train,y_train, cv=5,scoring='f1_macro')\n",
    "print([CVSLGBM2,np.average(CVSLGBM2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5653  2644   480]\n",
      " [ 2118 12045  1884]\n",
      " [   73  2019  3084]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.64407   0.72068   0.68022      7844\n",
      "           1    0.75061   0.72091   0.73546     16708\n",
      "           2    0.59583   0.56608   0.58057      5448\n",
      "\n",
      "    accuracy                        0.69273     30000\n",
      "   macro avg    0.66350   0.66922   0.66542     30000\n",
      "weighted avg    0.69464   0.69273   0.69289     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_cl = xgb.XGBClassifier(random_state =42,n_estimators=500, learning_rate=0.01, tree_method='gpu_hist')\n",
    "xgb_cl.fit(X_train,y_train)\n",
    "y_pred = xgb_cl .predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridxgb_cl = { \n",
    "    'max_depth' : np.linspace(15,20,6,dtype=int)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_xgb_cl = GridSearchCV(estimator=xgb_cl, param_grid=param_gridxgb_cl, cv= 5,scoring='f1_macro',n_jobs=8)\n",
    "CV_xgb_cl.fit(X_train, y_train)\n",
    "CV_xgb_cl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5564  2739   474]\n",
      " [ 1991 12242  1814]\n",
      " [   59  2056  3061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.63393   0.73076   0.67891      7614\n",
      "           1    0.76288   0.71855   0.74006     17037\n",
      "           2    0.59138   0.57226   0.58166      5349\n",
      "\n",
      "    accuracy                        0.69557     30000\n",
      "   macro avg    0.66273   0.67386   0.66688     30000\n",
      "weighted avg    0.69958   0.69557   0.69630     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_cl2 = xgb.XGBClassifier(random_state =42,n_estimators=500, learning_rate=0.01, tree_method='gpu_hist', max_depth=5)\n",
    "xgb_cl2.fit(X_train,y_train)\n",
    "y_pred = xgb_cl2 .predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_pred,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.65105555, 0.65338573, 0.66846296, 0.6544306 , 0.67753748]), 0.6609744606357798]\n"
     ]
    }
   ],
   "source": [
    "CVSxgb_cl2 = cross_val_score(xgb_cl2, X_train,y_train, cv=5,scoring='f1_macro')\n",
    "print([CVSxgb_cl2,np.average(CVSxgb_cl2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
